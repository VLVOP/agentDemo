"""
LLM Agent - è‡ªç„¶è¯­è¨€ç†è§£å’Œæ„å›¾è¯†åˆ«
"""
import os
import json
import re
from typing import Dict, List, Optional, Tuple
from pathlib import Path
import urllib.request
import urllib.error


class LLMAgent:
    """ä½¿ç”¨ LLM ç†è§£ç”¨æˆ·æ„å›¾å¹¶æ‰§è¡Œç›¸åº”æ“ä½œ"""
    
    def __init__(self, use_openai: bool = False):
        self.use_openai = use_openai
        self.model = "llama3"
        self.ollama_host = "http://localhost:11434"
        self.ollama_url = f"{self.ollama_host}/api/generate"
        self._requests = None
        self.ollama_available = False
        
        if use_openai:
            # ä½¿ç”¨ OpenAI API
            import openai
            self.client = openai.OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
            self.model = "gpt-3.5-turbo"
        else:
            # ä½¿ç”¨æœ¬åœ° Ollama
            self._requests = self._safe_import_requests()
            if self._check_ollama_alive():
                if self._ensure_ollama_model():
                    self.ollama_available = True
                    print("âœ… è¿æ¥åˆ°æœ¬åœ° Ollama")
                else:
                    self.ollama_url = None
            else:
                print("âš ï¸  æœªæ£€æµ‹åˆ° Ollamaï¼Œå°†ä½¿ç”¨è§„åˆ™åŒ¹é…æ¨¡å¼")
                self.ollama_url = None
    
    def parse_intent(self, user_input: str) -> Dict:
        """
        è§£æç”¨æˆ·æ„å›¾
        è¿”å›: {
            'action': 'search_paper' | 'search_image' | 'add_paper' | 'organize_papers' | 'chat',
            'query': str,
            'params': dict
        }
        """
        # å¦‚æœæœ‰ LLMï¼Œä½¿ç”¨ LLM è§£æ
        if self.use_openai or self.ollama_available:
            return self._parse_with_llm(user_input)
        else:
            # å¦åˆ™ä½¿ç”¨è§„åˆ™åŒ¹é…
            return self._parse_with_rules(user_input)
    
    def _parse_with_llm(self, user_input: str) -> Dict:
        """ä½¿ç”¨ LLM è§£ææ„å›¾"""
        
        system_prompt = """ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½æ–‡çŒ®å’Œå›¾åƒç®¡ç†åŠ©æ‰‹ã€‚ä½ éœ€è¦ç†è§£ç”¨æˆ·çš„è‡ªç„¶è¯­è¨€è¾“å…¥ï¼Œå¹¶å°†å…¶è½¬æ¢ä¸ºç»“æ„åŒ–çš„æ“ä½œæŒ‡ä»¤ã€‚

å¯ç”¨çš„æ“ä½œï¼š
1. search_paper - æœç´¢è®ºæ–‡ï¼ˆå…³é”®è¯ï¼šæœç´¢ã€æŸ¥æ‰¾ã€æ‰¾è®ºæ–‡ã€è®ºæ–‡ã€paperï¼‰
2. search_image - æœç´¢å›¾ç‰‡ï¼ˆå…³é”®è¯ï¼šå›¾ç‰‡ã€ç…§ç‰‡ã€å›¾åƒã€æ‰¾å›¾ã€imageï¼‰
3. add_paper - æ·»åŠ è®ºæ–‡ï¼ˆå…³é”®è¯ï¼šæ·»åŠ ã€ä¸Šä¼ ã€å¯¼å…¥è®ºæ–‡ï¼‰
4. organize_papers - æ•´ç†è®ºæ–‡ï¼ˆå…³é”®è¯ï¼šæ•´ç†ã€åˆ†ç±»ã€å½’æ¡£ï¼‰
5. chat - æ™®é€šå¯¹è¯

è¯·åˆ†æç”¨æˆ·è¾“å…¥ï¼Œè¿”å› JSON æ ¼å¼ï¼š
{
    "action": "æ“ä½œç±»å‹",
    "query": "æœç´¢å…³é”®è¯æˆ–å¯¹è¯å†…å®¹",
    "params": {"é¢å¤–å‚æ•°": "å€¼"}
}

ç¤ºä¾‹ï¼š
è¾“å…¥ï¼š"å¸®æˆ‘æ‰¾å…³äº Transformer çš„è®ºæ–‡"
è¾“å‡ºï¼š{"action": "search_paper", "query": "Transformer", "params": {}}

è¾“å…¥ï¼š"æœç´¢æµ·è¾¹æ—¥è½çš„å›¾ç‰‡"
è¾“å‡ºï¼š{"action": "search_image", "query": "æµ·è¾¹æ—¥è½", "params": {}}
"""
        
        try:
            if self.use_openai:
                # OpenAI API
                response = self.client.chat.completions.create(
                    model=self.model,
                    messages=[
                        {"role": "system", "content": system_prompt},
                        {"role": "user", "content": user_input}
                    ],
                    temperature=0.3,
                    max_tokens=200
                )
                result = response.choices[0].message.content
            else:
                # Ollama API
                payload = {
                    "model": self.model,
                    "prompt": f"{system_prompt}\n\nç”¨æˆ·è¾“å…¥ï¼š{user_input}\n\nè¯·è¿”å›JSONï¼š",
                    "stream": False,
                    "temperature": 0.3
                }
                response = self._http_post_json(self.ollama_url, payload, timeout=30)
                result = response.get('response', '')
            
            # è§£æ JSON
            json_match = re.search(r'\{.*\}', result, re.DOTALL)
            if json_match:
                return json.loads(json_match.group())
            else:
                return {"action": "chat", "query": user_input, "params": {}}
                
        except Exception as e:
            print(f"âš ï¸  LLM è§£æå¤±è´¥: {e}ï¼Œä½¿ç”¨è§„åˆ™åŒ¹é…")
            return self._parse_with_rules(user_input)
    
    def _parse_with_rules(self, user_input: str) -> Dict:
        """ä½¿ç”¨è§„åˆ™åŒ¹é…è§£ææ„å›¾ï¼ˆä¸ä¾èµ– LLMï¼‰"""
        user_input_lower = user_input.lower()
        
        # æœç´¢è®ºæ–‡
        paper_keywords = ['è®ºæ–‡', 'æ–‡çŒ®', 'paper', 'æœç´¢', 'æŸ¥æ‰¾', 'æ‰¾', 'search', 
                         'transformer', 'æ·±åº¦å­¦ä¹ ', 'deep learning', 'neural']
        if any(kw in user_input_lower for kw in paper_keywords):
            if 'å›¾' not in user_input_lower and 'ç…§ç‰‡' not in user_input_lower:
                # æå–å…³é”®è¯
                query = self._extract_query(user_input)
                return {
                    "action": "search_paper",
                    "query": query,
                    "params": {"top_k": 5}
                }
        
        # æœç´¢å›¾ç‰‡
        image_keywords = ['å›¾ç‰‡', 'å›¾åƒ', 'ç…§ç‰‡', 'image', 'photo', 'æ‰¾å›¾', 'æ—¥è½', 'å±±', 'çŒ«']
        if any(kw in user_input_lower for kw in image_keywords):
            query = self._extract_query(user_input)
            return {
                "action": "search_image",
                "query": query,
                "params": {"top_k": 5}
            }
        
        # æ·»åŠ è®ºæ–‡
        add_keywords = ['æ·»åŠ ', 'ä¸Šä¼ ', 'å¯¼å…¥', 'add', 'æ–°å¢']
        if any(kw in user_input_lower for kw in add_keywords):
            return {
                "action": "add_paper",
                "query": user_input,
                "params": {"topics": "CV,NLP,RL"}
            }
        
        # æ•´ç†è®ºæ–‡
        organize_keywords = ['æ•´ç†', 'åˆ†ç±»', 'å½’æ¡£', 'organize', 'æ‰¹é‡']
        if any(kw in user_input_lower for kw in organize_keywords):
            return {
                "action": "organize_papers",
                "query": user_input,
                "params": {"topics": "CV,NLP,RL"}
            }
        
        # é»˜è®¤ä¸ºå¯¹è¯
        return {
            "action": "chat",
            "query": user_input,
            "params": {}
        }
    
    def _extract_query(self, text: str) -> str:
        """ä»æ–‡æœ¬ä¸­æå–æœç´¢å…³é”®è¯"""
        # ç§»é™¤å¸¸è§çš„åŠ¨è¯å’Œä»‹è¯
        stop_words = ['å¸®æˆ‘', 'è¯·', 'æ‰¾', 'æœç´¢', 'æŸ¥æ‰¾', 'å…³äº', 'çš„', 'å›¾ç‰‡', 'ç…§ç‰‡', 
                     'è®ºæ–‡', 'æ–‡çŒ®', 'search', 'find', 'about', 'the', 'a', 'an']
        
        words = text.split()
        query_words = [w for w in words if w.lower() not in stop_words]
        return ' '.join(query_words) if query_words else text
    
    def _safe_import_requests(self):
        try:
            import requests  # type: ignore
            return requests
        except Exception:
            return None
    
    def _http_get_json(self, url: str, timeout: Optional[float] = None) -> Dict:
        if self._requests:
            response = self._requests.get(url, timeout=timeout)
            response.raise_for_status()
            return response.json()
        
        request = urllib.request.Request(url)
        if timeout is None:
            with urllib.request.urlopen(request) as resp:
                raw = resp.read()
        else:
            with urllib.request.urlopen(request, timeout=timeout) as resp:
                raw = resp.read()
        return json.loads(raw.decode("utf-8")) if raw else {}
    
    def _http_post_json(self, url: str, payload: Dict, timeout: Optional[float] = None) -> Dict:
        if self._requests:
            response = self._requests.post(url, json=payload, timeout=timeout)
            response.raise_for_status()
            return response.json()
        
        data = json.dumps(payload).encode("utf-8")
        request = urllib.request.Request(
            url,
            data=data,
            headers={"Content-Type": "application/json"}
        )
        if timeout is None:
            with urllib.request.urlopen(request) as resp:
                raw = resp.read()
        else:
            with urllib.request.urlopen(request, timeout=timeout) as resp:
                raw = resp.read()
        return json.loads(raw.decode("utf-8")) if raw else {}
    
    def _check_ollama_alive(self) -> bool:
        try:
            self._http_get_json(f"{self.ollama_host}/api/tags", timeout=3)
            return True
        except Exception:
            return False
    
    def _ensure_ollama_model(self) -> bool:
        try:
            tags = self._http_get_json(f"{self.ollama_host}/api/tags", timeout=5) or {}
            models = tags.get("models") or tags.get("data") or []
            if any(m.get("name") == self.model for m in models):
                return True
            
            print(f"â¬‡ï¸  è‡ªåŠ¨æ‹‰å–æ¨¡å‹ {self.model} ...")
            pulled = self._pull_model()
            if pulled:
                print(f"âœ… æ¨¡å‹ {self.model} å·²å°±ç»ª")
            else:
                print(f"âš ï¸  æ‹‰å–æ¨¡å‹ {self.model} å¤±è´¥ï¼Œå°†ä½¿ç”¨è§„åˆ™åŒ¹é…æ¨¡å¼")
            return pulled
        except Exception as exc:
            print(f"âš ï¸  æ£€æŸ¥/æ‹‰å–æ¨¡å‹å¤±è´¥: {exc}")
            return False
    
    def _pull_model(self) -> bool:
        pull_url = f"{self.ollama_host}/api/pull"
        payload = {"model": self.model}
        
        try:
            if self._requests:
                with self._requests.post(pull_url, json=payload, stream=True, timeout=None) as resp:
                    resp.raise_for_status()
                    for line in resp.iter_lines():
                        if not line:
                            continue
                        try:
                            decoded = line.decode("utf-8") if isinstance(line, bytes) else line
                            data = json.loads(decoded)
                        except Exception:
                            continue
                        if data.get("status") == "success":
                            return True
                return False
            
            request = urllib.request.Request(
                pull_url,
                data=json.dumps(payload).encode("utf-8"),
                headers={"Content-Type": "application/json"}
            )
            with urllib.request.urlopen(request) as resp:
                raw = resp.read()
            for line in raw.splitlines()[::-1]:
                try:
                    decoded = line.decode("utf-8") if isinstance(line, (bytes, bytearray)) else line
                    data = json.loads(decoded)
                except Exception:
                    continue
                if data.get("status") == "success":
                    return True
            return False
        except Exception as exc:
            print(f"âš ï¸  è‡ªåŠ¨æ‹‰å–æ¨¡å‹å¤±è´¥: {exc}")
            return False
    
    def generate_response(self, action: str, results: List, query: str) -> str:
        """ç”Ÿæˆå‹å¥½çš„å“åº”"""
        if action == "search_paper":
            if results:
                response = f"ğŸ” æ‰¾åˆ° {len(results)} ç¯‡ç›¸å…³è®ºæ–‡ï¼š\n\n"
                for i, result in enumerate(results[:3], 1):
                    filename = result['metadata']['filename']
                    topic = result['metadata'].get('topic', 'Unknown')
                    similarity = 1 - result.get('distance', 0)
                    response += f"{i}. ğŸ“„ {filename}\n"
                    response += f"   ä¸»é¢˜: {topic} | ç›¸å…³åº¦: {similarity:.1%}\n\n"
                return response
            else:
                return "ğŸ˜” æ²¡æœ‰æ‰¾åˆ°ç›¸å…³è®ºæ–‡ï¼Œè¯•è¯•å…¶ä»–å…³é”®è¯ï¼Ÿ"
        
        elif action == "search_image":
            if results:
                response = f"ğŸ–¼ï¸  æ‰¾åˆ° {len(results)} å¼ ç›¸å…³å›¾ç‰‡ï¼š\n\n"
                for i, result in enumerate(results[:3], 1):
                    filename = result['metadata']['filename']
                    similarity = 1 - result.get('distance', 0)
                    response += f"{i}. ğŸ¨ {filename} (ç›¸å…³åº¦: {similarity:.1%})\n"
                return response
            else:
                return "ğŸ˜” æ²¡æœ‰æ‰¾åˆ°ç›¸å…³å›¾ç‰‡ï¼Œè¯•è¯•å…¶ä»–æè¿°ï¼Ÿ"
        
        elif action == "chat":
            return "æˆ‘æ˜¯ä½ çš„æ–‡çŒ®å’Œå›¾åƒç®¡ç†åŠ©æ‰‹ï¼ä½ å¯ä»¥ï¼š\n\n" \
                   "ğŸ“„ æœç´¢è®ºæ–‡ï¼šã€Œæ‰¾å…³äº Transformer çš„è®ºæ–‡ã€\n" \
                   "ğŸ–¼ï¸  æœç´¢å›¾ç‰‡ï¼šã€Œæ‰¾æ—¥è½çš„ç…§ç‰‡ã€\n" \
                   "â• æ·»åŠ è®ºæ–‡ï¼šã€Œæ·»åŠ è¿™ç¯‡è®ºæ–‡ path/to/paper.pdfã€\n" \
                   "ğŸ“ æ•´ç†è®ºæ–‡ï¼šã€Œæ•´ç†æˆ‘çš„è®ºæ–‡åº“ã€"
        
        return "æ“ä½œå®Œæˆï¼"


def interactive_chat():
    """äº¤äº’å¼å¯¹è¯æ¨¡å¼"""
    from app.embeddings import TextEmbedder, ImageEmbedder
    from app.chroma_store import ChromaStore
    
    print("ğŸ¤– æ™ºèƒ½åŠ©æ‰‹å¯åŠ¨...")
    print("=" * 50)
    
    # åˆå§‹åŒ–
    agent = LLMAgent(use_openai=False)
    text_embedder = TextEmbedder()
    image_embedder = ImageEmbedder()
    store = ChromaStore()
    
    print("\nğŸ’¬ ä½ å¯ä»¥ç”¨è‡ªç„¶è¯­è¨€è·Ÿæˆ‘å¯¹è¯ï¼")
    print("ç¤ºä¾‹:")
    print("  - å¸®æˆ‘æ‰¾å…³äºæ·±åº¦å­¦ä¹ çš„è®ºæ–‡")
    print("  - æœç´¢æµ·è¾¹æ—¥è½çš„å›¾ç‰‡")
    print("  - æ‰¾ä¸€ä¸‹ Transformer ç›¸å…³çš„æ–‡çŒ®")
    print("\nè¾“å…¥ 'quit' æˆ– 'exit' é€€å‡º\n")
    
    while True:
        try:
            user_input = input("ğŸ‘¤ ä½ : ").strip()
            
            if not user_input:
                continue
            
            if user_input.lower() in ['quit', 'exit', 'é€€å‡º', 'bye']:
                print("ğŸ‘‹ å†è§ï¼")
                break
            
            # è§£ææ„å›¾
            intent = agent.parse_intent(user_input)
            action = intent['action']
            query = intent['query']
            
            print(f"\nğŸ¤” ç†è§£: [{action}] {query}")
            print("ğŸ”„ å¤„ç†ä¸­...\n")
            
            # æ‰§è¡Œæ“ä½œ
            if action == "search_paper":
                embedding = text_embedder.embed(query)
                results = store.search('papers', embedding, n_results=5)
                response = agent.generate_response(action, results, query)
                print(f"ğŸ¤– åŠ©æ‰‹: {response}")
            
            elif action == "search_image":
                embedding = image_embedder.embed_text(query)
                results = store.search('images', embedding, n_results=5)
                response = agent.generate_response(action, results, query)
                print(f"ğŸ¤– åŠ©æ‰‹: {response}")
            
            else:
                response = agent.generate_response(action, [], query)
                print(f"ğŸ¤– åŠ©æ‰‹: {response}")
            
            print()
            
        except KeyboardInterrupt:
            print("\n\nğŸ‘‹ å†è§ï¼")
            break
        except Exception as e:
            print(f"âŒ é”™è¯¯: {e}\n")


if __name__ == "__main__":
    interactive_chat()
